# -*- coding: utf-8 -*-
"""NeuralNetwork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TmpAt8PASsW9lqw3hxS60z9_fObN8D7g
"""

import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np
import random

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

type(x_train)

class_names = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
class_nums = len(class_names)

from typing import Optional
def plot_data(x_data: np.ndarray, y_data: np.ndarray, y_proba: Optional[np.ndarray] = None) -> None:
  nrows, ncols = 2, 5
  fig, axes = plt.subplots(nrows, ncols)

  len_x = x_data.shape[0]
  for idx in range(nrows*ncols):
    ax = axes[idx // ncols, idx % ncols]

    img_idx = random.randint(0, len_x)

    ax.imshow(x_data[img_idx], cmap='gray')
    ax.set(xticks=[], yticks=[])
    color = 'green'
    true_label_str = f"True: {class_names[y_data[img_idx]]}"

    if y_proba is not None :
      predicted_idx = np.argmax(y_proba[img_idx])
      predicted_lable = class_names[predicted_idx]
      color = 'red' if predicted_idx != y_data[img_idx] else color
      predicted_lable_str = f"\nPredicted: {predicted_lable}"

    img_title = true_label_str if y_proba is None else true_label_str + predicted_lable_str
    ax.set_xlabel(img_title, color = color, fontsize = 12)
plot_data(x_train, y_train)

x_train = x_train.astype(np.float32) / 255
x_test = x_test.astype(np.float32) / 255

x_train = np.expand_dims(x_train, axis = -1)
x_test = np.expand_dims(x_test, axis = -1)

y_train_label = keras.utils.to_categorical(y_train, class_nums)
y_test_label = keras.utils.to_categorical(y_test, class_nums)

input_shape = (28, 28, 1)

model = keras.models.Sequential([
    layers.Flatten(input_shape = input_shape),
    layers.Dense(512, activation = 'relu'),
    layers.Dense(256, activation = 'relu'),
    layers.Dense(class_nums, activation = 'softmax')
])

model.summary()

model.compile(optimizer='rmsprop',
              loss = 'categorical_crossentropy',
              metrics = 'accuracy')

epochs = 10
batch_size = 256
history = model.fit(x_train, y_train_label,
          epochs = epochs,
          batch_size = batch_size,
          validation_split = 0.1
          )

history_dict = history.history

train_loss, val_loss = history_dict['loss'], history_dict['val_loss']
train_acc, val_acc = history_dict['accuracy'], history_dict['val_accuracy']

fid, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))
epoch_run = [i+1 for i in range(epochs)]

ax1.plot(epoch_run, train_loss, label = "Training Loss")
ax1.plot(epoch_run, val_loss, label = "Validation Loss")
ax1.set(title='Traning & Validation Loss', xlabel = 'eposch', ylabel = 'loss')
ax1.legend()

ax2.plot(epoch_run, train_acc, label = "Training Accuracy")
ax2.plot(epoch_run, val_acc, label = "Validation Accuracy")
ax2.set(title='Traning & Validation accuracy', xlabel = 'eposch', ylabel = 'accuracy')
ax2.legend()

plt.show()

score = model.evaluate(x_test, y_test_label)

print(f"Test Loss: {score[0]: .4f}")
print(f"Test accuracy: {score[1]: .4f}")

x_sample = x_test[:3]
y_proba = model.predict(x_sample)

prediction = np.argmax(y_proba, axis = 1)

[class_names[pred] for pred in prediction]

y_proba = model.predict(x_test)

plot_data(x_test, y_test, y_proba)